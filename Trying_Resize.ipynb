{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "vital-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from batchgenerators.augmentations.crop_and_pad_augmentations import crop\n",
    "from batchgenerators.dataloading import MultiThreadedAugmenter, SingleThreadedAugmenter\n",
    "from config import brats_preprocessed_folder, num_threads_for_brats_example\n",
    "# from batchgenerators.examples.brats2017.config import brats_preprocessed_folder, num_threads_for_brats_example\n",
    "from batchgenerators.transforms import Compose\n",
    "from batchgenerators.utilities.data_splitting import get_split_deterministic\n",
    "from batchgenerators.utilities.file_and_folder_operations import *\n",
    "import numpy as np\n",
    "from batchgenerators.dataloading.data_loader import DataLoader\n",
    "from batchgenerators.augmentations.utils import pad_nd_image\n",
    "from batchgenerators.augmentations.spatial_transformations import augment_resize\n",
    "from batchgenerators.transforms.spatial_transforms import SpatialTransform_2, MirrorTransform\n",
    "from batchgenerators.transforms.color_transforms import BrightnessMultiplicativeTransform, GammaTransform, BrightnessTransform\n",
    "from batchgenerators.transforms.noise_transforms import GaussianNoiseTransform, GaussianBlurTransform, RicianNoiseTransform\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "from brats_data_loader import BRATSDataLoader\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "spoken-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_indices = {\n",
    "    't1': 0,\n",
    "    't1c': 1,\n",
    "    't2': 2,\n",
    "    'flair': 3,\n",
    "    'seg': 4\n",
    "}\n",
    "\n",
    "def get_train_transform(patch_size):\n",
    "    # we now create a list of transforms. These are not necessarily the best transforms to use for BraTS, this is just\n",
    "    # to showcase some things\n",
    "    tr_transforms = []\n",
    "\n",
    "    # the first thing we want to run is the SpatialTransform. It reduces the size of our data to patch_size and thus\n",
    "    # also reduces the computational cost of all subsequent operations. All subsequent operations do not modify the\n",
    "    # shape and do not transform spatially, so no border artifacts will be introduced\n",
    "    # Here we use the new SpatialTransform_2 which uses a new way of parameterizing elastic_deform\n",
    "    # We use all spatial transformations with a probability of 0.2 per sample. This means that 1 - (1 - 0.1) ** 3 = 27%\n",
    "    # of samples will be augmented, the rest will just be cropped\n",
    "\n",
    "    tr_transforms.append(\n",
    "        SpatialTransform_2(\n",
    "            patch_size, [i // 2 for i in patch_size],\n",
    "            do_elastic_deform=True, deformation_scale=(0, 0.25),\n",
    "            do_rotation=True,\n",
    "            angle_x=(- 15 / 360. * 2 * np.pi, 15 / 360. * 2 * np.pi),\n",
    "            angle_y=(- 15 / 360. * 2 * np.pi, 15 / 360. * 2 * np.pi),\n",
    "            angle_z=(- 15 / 360. * 2 * np.pi, 15 / 360. * 2 * np.pi),\n",
    "            do_scale=True, scale=(0.65, 1.60),\n",
    "            border_mode_data='constant', border_cval_data=0,\n",
    "            border_mode_seg='constant', border_cval_seg=0,\n",
    "            order_seg=1, order_data=3,\n",
    "            random_crop=True,\n",
    "            p_el_per_sample=0.1, p_rot_per_sample=0.1, p_scale_per_sample=0.1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # now we mirror along all axes\n",
    "    tr_transforms.append(MirrorTransform(axes=(0, 1, 2)))\n",
    "\n",
    "    # COLOR TRANSFORMS - brightness transform for 15% of samples \n",
    "    # tr_transforms.append(BrightnessMultiplicativeTransform((0.7, 1.5), per_channel=True, p_per_sample=0.15))\n",
    "    tr_transforms.append(BrightnessTransform(mu=0, sigma=0.5, p_per_sample=0.3))\n",
    "\n",
    "    # COLOR TRANSFORMS - gamma transform. This is a nonlinear transformation of intensity values\n",
    "    # (https://en.wikipedia.org/wiki/Gamma_correction)\n",
    "    tr_transforms.append(GammaTransform(gamma_range=(0.5, 2), invert_image=False, per_channel=True, p_per_sample=0.15))\n",
    "    # we can also invert the image, apply the transform and then invert back\n",
    "    tr_transforms.append(GammaTransform(gamma_range=(0.5, 2), invert_image=True, per_channel=True, p_per_sample=0.15))\n",
    "\n",
    "    # Gaussian Noise and RicianNoise\n",
    "    # tr_transforms.append(GaussianNoiseTransform(noise_variance=(0, 0.05), p_per_sample=0.15))\n",
    "    # tr_transforms.append(GaussianNoiseTransform(noise_variance=(0, 0.05), p_per_sample=0.15))\n",
    "    tr_transforms.append(RicianNoiseTransform(noise_variance=(0, 0.05), p_per_sample=0.15))\n",
    "\n",
    "    # blurring. Some BraTS cases have very blurry modalities. This can simulate more patients with this problem and\n",
    "    # thus make the model more robust to it\n",
    "    # tr_transforms.append(GaussianBlurTransform(blur_sigma=(0.5, 1.5), different_sigma_per_channel=True,\n",
    "    #                                            p_per_channel=0.5, p_per_sample=0.15))\n",
    "    tr_transforms.append(GaussianBlurTransform(blur_sigma=(0.5, 1.5), different_sigma_per_channel=True,\n",
    "                                               p_per_channel=0.7, p_per_sample=0.30))\n",
    "    \n",
    "\n",
    "    # now we compose these transforms together\n",
    "    tr_transforms = Compose(tr_transforms)\n",
    "    return tr_transforms\n",
    "\n",
    "\n",
    "def get_list_of_patients(preprocessed_data_folder):\n",
    "    npy_files = subfiles(preprocessed_data_folder, suffix=\".npy\", join=True)\n",
    "    # remove npy file extension\n",
    "    patients = [i[:-4] for i in npy_files]\n",
    "    return patients\n",
    "\n",
    "#NEW\n",
    "def iterate_through_patients(patients, in_channels):\n",
    "    in_channels = [channel_indices[i] for i in in_channels]\n",
    "    \n",
    "    for p in patients:\n",
    "        patient_data, meta_data = BRATSDataLoader.load_patient(p)\n",
    "        \n",
    "        # patient_data = BRATSDataLoader.load_patient(p)[0][in_channels][None]\n",
    "        # meta_data = BRATSDataLoader.load_patient(p)[1]\n",
    "        yield (patient_data[in_channels][None], meta_data)\n",
    "        \n",
    "def iterate_through_patients_transforms(patients, in_channels):\n",
    "    patient_data_ls = []\n",
    "    meta_data_ls = []\n",
    "    in_channels = [channel_indices[i] for i in in_channels]\n",
    "    \n",
    "    for p in patients:\n",
    "        patient_data, meta_data = BRATSDataLoader.load_patient(p)\n",
    "        \n",
    "        # patient_data = BRATSDataLoader.load_patient(p)[0][in_channels][None]\n",
    "        # meta_data = BRATSDataLoader.load_patient(p)[1]\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        yield (patient_data[in_channels][None], meta_data)        \n",
    "        return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-wales",
   "metadata": {},
   "source": [
    "# Load in patient data here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "southeast-exemption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training patients: 10\n",
      "The number of test patients: 5\n"
     ]
    }
   ],
   "source": [
    "base = 'brats_data_preprocessed/'\n",
    "\n",
    "patients = get_list_of_patients(base+\"Brats20TrainingData\")\n",
    "patients_train = patients\n",
    "print(f\"The number of training patients: {len(patients_train)}\")\n",
    "\n",
    "\n",
    "test_patients = get_list_of_patients(base + \"Brats20ValidationData\")\n",
    "target_patients = test_patients[0:5]\n",
    "print(f\"The number of test patients: {len(target_patients)}\")\n",
    "\n",
    "\n",
    "batch_size = 12\n",
    "patch_size = [24, 128, 128]\n",
    "in_channels = ['t1c', 't2', 'flair']\n",
    "\n",
    "train_dl = BRATSDataLoader(\n",
    "    patients_train,\n",
    "    batch_size=batch_size,\n",
    "    patch_size=patch_size,\n",
    "    in_channels=in_channels\n",
    ")\n",
    "\n",
    "\n",
    "tr_transforms = get_train_transform(patch_size)\n",
    "\n",
    "tr_gen = MultiThreadedAugmenter(train_dl, tr_transforms, num_processes=4, # num_processes=4\n",
    "                                num_cached_per_queue=3,\n",
    "                                seeds=None, pin_memory=False)\n",
    "\n",
    "\n",
    "#Target shape in predict patient in patches is: [1, 3, 144, 192, 192]\n",
    "# Training data shape is (12, 3, 24, 128, 128), (batch_size, channels, depth, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "apparent-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "patdata, metadata = BRATSDataLoader.load_patient(target_patients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "varied-patrick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spacing': array([1., 1., 1.]),\n",
       " 'direction': (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0),\n",
       " 'origin': (-0.0, -239.0, 0.0),\n",
       " 'original_shape': (155, 240, 240),\n",
       " 'nonzero_region': array([[  0, 139],\n",
       "        [ 35, 220],\n",
       "        [ 52, 184]], dtype=int64)}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "greek-sarah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spacing': array([1., 1., 1.]),\n",
       " 'direction': (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0),\n",
       " 'origin': (-0.0, -239.0, 0.0),\n",
       " 'original_shape': (155, 240, 240),\n",
       " 'nonzero_region': array([[  2, 135],\n",
       "        [ 48, 207],\n",
       "        [ 46, 191]], dtype=int64)}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "convinced-suspension",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch size is: [140, 186, 133]\n",
      "Patient BraTS20_Validation_001\n",
      "['brats_data_preprocessed/Brats20ValidationData\\\\BraTS20_Validation_001'] (1, 3, 140, 186, 133)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 1/5 [07:57<31:50, 477.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch size is: [142, 190, 143]\n",
      "Patient BraTS20_Validation_002\n",
      "['brats_data_preprocessed/Brats20ValidationData\\\\BraTS20_Validation_002'] (1, 3, 140, 186, 133)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [14:10<20:48, 416.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch size is: [140, 165, 125]\n",
      "Patient BraTS20_Validation_003\n",
      "['brats_data_preprocessed/Brats20ValidationData\\\\BraTS20_Validation_003'] (1, 3, 140, 186, 133)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [20:56<13:42, 411.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch size is: [138, 180, 132]\n",
      "Patient BraTS20_Validation_004\n",
      "['brats_data_preprocessed/Brats20ValidationData\\\\BraTS20_Validation_004'] (1, 3, 140, 186, 133)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████  | 4/5 [35:23<09:51, 591.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch size is: [139, 163, 147]\n",
      "Patient BraTS20_Validation_005\n",
      "['brats_data_preprocessed/Brats20ValidationData\\\\BraTS20_Validation_005'] (1, 3, 140, 186, 133)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [41:36<00:00, 499.39s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tr_transforms = get_train_transform(patch_size)\n",
    "\n",
    "for patient in tqdm(target_patients):\n",
    "    \n",
    "    original_size, metadata_old = BRATSDataLoader.load_patient(patient)\n",
    "    patch_size = list(original_size[0,:,:,:].shape)\n",
    "    print(f\"Patch size is: {patch_size}\")\n",
    "    \n",
    "    name = patient.split(\"\\\\\")[-1]\n",
    "    print(f\"Patient {name}\")\n",
    "    \n",
    "    test_dl_new = BRATSDataLoader(\n",
    "    [patient],\n",
    "    batch_size=1,\n",
    "    patch_size=patch_size,\n",
    "    in_channels=in_channels\n",
    "    ) \n",
    "\n",
    "    # What if we apply the same process to the test data first? \n",
    "    test_gen_new =  MultiThreadedAugmenter(test_dl_new, tr_transforms, num_processes=4, # num_processes=4\n",
    "                                    num_cached_per_queue=3,\n",
    "                                    seeds=None, pin_memory=False)\n",
    "\n",
    "#     test_gen_new.restart()\n",
    "    batch = next(test_gen_new)\n",
    "    patient_data = batch[\"data\"]\n",
    "    meta_data = batch[\"metadata\"][0]\n",
    "    name = batch[\"names\"]\n",
    "    print(name, patient_data.shape)\n",
    "    \n",
    "    test_gen_new._finish()\n",
    "    del test_dl_new\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "general-majority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 24, 128, 128)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "determined-complaint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spacing': array([1., 1., 1.]),\n",
       " 'direction': (1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0),\n",
       " 'origin': (-0.0, -239.0, 0.0),\n",
       " 'original_shape': (155, 240, 240),\n",
       " 'nonzero_region': array([[  0, 138],\n",
       "        [ 45, 207],\n",
       "        [ 44, 190]], dtype=int64)}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"metadata\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "experimental-floor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:MultiThreadedGenerator: caught exception: (<class 'KeyboardInterrupt'>, KeyboardInterrupt(), <traceback object at 0x0000025D49827F00>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\FYP\\lib\\site-packages\\batchgenerators\\dataloading\\multi_threaded_augmenter.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_next_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FYP\\lib\\site-packages\\batchgenerators\\dataloading\\multi_threaded_augmenter.py\u001b[0m in \u001b[0;36m__get_next_item\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-8224bdf620ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m#     print(f\"Patient {name}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_gen_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mpatient_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mmeta_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"metadata\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FYP\\lib\\site-packages\\batchgenerators\\dataloading\\multi_threaded_augmenter.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MultiThreadedGenerator: caught exception: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_finish\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\FYP\\lib\\site-packages\\batchgenerators\\dataloading\\multi_threaded_augmenter.py\u001b[0m in \u001b[0;36m_finish\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m             \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_processes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_dl_new = BRATSDataLoader(\n",
    "target_patients,\n",
    "batch_size=1,\n",
    "patch_size=patch_size,\n",
    "in_channels=in_channels\n",
    ") \n",
    "\n",
    "# What if we apply the same process to the test data first? \n",
    "test_gen_new =  MultiThreadedAugmenter(test_dl_new, tr_transforms, num_processes=4, # num_processes=4\n",
    "                                num_cached_per_queue=3,\n",
    "                                seeds=None, pin_memory=False)\n",
    "\n",
    "for patient in range(len(target_patients)):\n",
    "#     name = patient.split(\"\\\\\")[-1]\n",
    "#     print(f\"Patient {name}\")\n",
    "\n",
    "    batch = next(test_gen_new)\n",
    "    patient_data = batch[\"data\"]\n",
    "    meta_data = batch[\"metadata\"]\n",
    "    name = batch[\"names\"]\n",
    "    print(name, patient_data.shape)\n",
    "\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "stringlol = \"brats_data_preprocessed/Brats20ValidationData/BraTS20_Validation_001\"\n",
    "\n",
    "stringlol.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(test_gen)['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen2 = SingleThreadedAugmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, batch in enumerate(test_gen):\n",
    "    print(idx,batch[\"names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-blake",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(test_gen):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-alabama",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(tr_gen)\n",
    "batch[\"data\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(tr_gen)\n",
    "batch[\"data\"][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_pat = batch[\"data\"][0][0]\n",
    "some_pat = np.moveaxis(some_pat, 0, -1)\n",
    "print(some_pat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slices(slices):\n",
    "    \"\"\" Function to display row of image slices \"\"\"\n",
    "    fig, axes = plt.subplots(1, len(slices))\n",
    "    for i, slice in enumerate(slices):\n",
    "        axes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_0 = some_pat[65, :, :]\n",
    "slice_1 = some_pat[:, 65, :]\n",
    "slice_2 = some_pat[:, :, 5]\n",
    "\n",
    "show_slices([slice_0,slice_1,slice_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_0 = some_pat[65, :, :]\n",
    "slice_1 = some_pat[:, 65, :]\n",
    "slice_2 = some_pat[:, :, 15]\n",
    "\n",
    "show_slices([slice_0,slice_1,slice_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl.generate_train_batch()[\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iterate_through_patients(target_patients, in_channels))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "nib.load(\"MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_t1.nii.gz\").get_fdata().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "data , metadata = BRATSDataLoader.load_patient(base+\"Brats20TrainingData/BraTS20_Training_001\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data , metadata = BRATSDataLoader.load_patient(base+\"Brats20ValidationData/BraTS20_Validation_001\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_nd_image(data, [144, 192, 192]).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
